# ConcurrentHashMap

## 一、ConcurrentHashMap 概述

- **定义**：`java.util.concurrent.ConcurrentHashMap` 是 Java 并发包提供的线程安全的哈希表实现，专为高并发场景设计
- **继承关系**：继承自 `AbstractMap`，实现了 `ConcurrentMap`、`Serializable` 接口
- **核心特点**：
  - 线程安全（比 Hashtable 更高效的并发实现）
  - 支持高并发读写操作
  - 允许 null 值，但不允许 null 键
  - 无序存储（插入顺序与遍历顺序不一致）

## 二、不同版本的实现差异

### 1. JDK 7 实现
- **分段锁机制**：
  - 将哈希表分为多个 Segment（段），默认有16个段
  - 每个 Segment 是一个独立的哈希表，有自己的锁
  - 不同段之间的操作可以并行执行
- **结构**：`Segment[]` + `HashEntry[]` + 链表

### 2. JDK 8+ 实现
- **CAS + synchronized 机制**：
  - 放弃了 Segment 纬度的锁，采用更细粒度的锁
  - 使用 CAS 操作进行无锁更新
  - 仅在必要时（如链表头节点）使用 synchronized
- **结构**：Node[] + 链表/红黑树（与 HashMap 类似）

## 三、JDK 8+ 核心数据结构

### 1. 基本结构
- **Node 数组**：作为哈希桶数组
- **链表**：处理哈希冲突
- **红黑树**：当链表长度超过阈值（8）时转换为红黑树

### 2. 核心节点类型
- **Node**：基础存储节点，val 和 next 字段使用 volatile 保证可见性
- **TreeNode**：红黑树节点，用于高效查询
- **ForwardingNode**：扩容标记节点，指向新表，引导线程访问新表

## 四、核心参数与构造函数

### 1. 关键参数

ConcurrentHashMap 的主要参数控制容量、并发度和性能（JDK 8+版本）：

- **初始容量**：默认 16，是Node数组的初始大小（JDK 7中Node数组默认容量也是16），建议根据预期数据量设置
- **并发等级**：JDK 7特有参数，控制Segment的数量，默认16，用于设置并发线程数的预估上限（JDK 8中已移除，因为不再使用分段锁机制）
- **负载因子**：默认 0.75，平衡空间利用率和查询性能
- **树化阈值**：链表转红黑树的长度阈值，默认 8
- **反树化阈值**：红黑树转回链表的长度阈值，默认 6
- **最小树化容量**：表需要达到此容量才会进行树化，默认 64
- **sizeCtl**：内部核心控制参数，用于控制初始化和扩容，不同取值有不同含义：
  - 0：表示未初始化
  - 正数：表示下次扩容的阈值（当元素数量超过此值时触发扩容）
  - 负数：表示正在进行初始化或扩容操作，高位部分表示扩容戳，低位部分表示参与扩容的线程数

### 2. 主要构造函数

提供多种构造函数以满足不同初始化需求：

- 无参构造：使用默认参数
- 指定初始容量
- 从其他 Map 初始化
- 同时指定容量、负载因子和并发等级

## 五、JDK 8+ 关键方法实现原理

### 1. put 方法

put 方法的核心流程：

1. **检查参数**：不允许键值为 null
2. **计算哈希**：使用 spread 算法处理哈希码
3. **检查表初始化**：未初始化则调用 initTable() 初始化
4. **插入数据**：
   - 桶为空：使用 CAS 操作直接插入
   - 表在扩容：参与扩容（帮助迁移数据），然后在**当前操作的桶迁移完成后**将新数据插入到正确的位置
   - 正常插入：锁定桶的头节点，根据节点类型执行链表或红黑树操作
5. **可能的树化**：链表长度超过阈值时转为红黑树
6. **扩容检查**：数据插入完成后，检查元素总数是否超过 sizeCtl（扩容阈值），如果超过则触发扩容

核心特点：仅锁定当前操作的桶，而非整个表，提高并发性能，扩容触发时机在数据插入完成后

### 2. get 方法

get 方法实现简洁高效：

1. **计算哈希**：确定目标桶位置
2. **直接查询**：无需加锁，根据节点类型进行查找
3. **三种情况**：
   - 头节点匹配：直接返回
   - 红黑树节点：调用 find 方法查找
   - 链表节点：遍历链表查找

特点：无锁设计，读操作不会阻塞，性能优秀

### 3. 扩容机制

ConcurrentHashMap 采用**并发扩容**设计，具体扩容时机和流程如下：

1. **触发条件**：
   - 当元素总数超过阈值（容量 * 负载因子）时触发扩容，具体来说，当 put 操作导致元素数量超过 sizeCtl 时触发

2. **扩容流程**：
   - 创建新表（容量翻倍）
   - 使用 ForwardingNode 标记已处理桶
   - 多线程协作迁移数据，每个线程处理一部分桶

3. **关键机制**：
   - 工作窃取：未分配的桶可被其他线程处理
   - 标记转发：已迁移桶的查询会转发到新表
   - 帮助扩容：其他线程发现正在扩容时会主动参与迁移工作

## 六、线程安全机制

### 1. JDK 7 线程安全：分段锁

- 将整个哈希表分为多个 Segment
- 每个 Segment 独立加锁，互不影响
- 不同 Segment 上的操作可以并行执行
- 缺点：
  - 内存占用较大（每个 Segment 都有独立的数组和锁）
  - 并发度受限于 Segment 数量

### 2. JDK 8+ 线程安全：CAS + synchronized

JDK 8+的ConcurrentHashMap采用了更先进的并发控制机制，结合了无锁操作和细粒度锁定，大幅提升了并发性能：

#### 核心机制详解

- **CAS (Compare-And-Swap) 无锁操作**：
  - **原理**：基于CPU原子指令实现的乐观锁，通过比较内存值与预期值，若相等则更新并返回成功
  - **应用场景**：数组初始化、插入空桶、更新计数等简单操作
  - **实现**：使用`Unsafe`类的`compareAndSwapObject`、`compareAndSwapInt`等方法
  - **优势**：无阻塞、无上下文切换开销，高并发下性能优秀

- **synchronized 细粒度锁**：
  - **锁定范围**：仅在必要时锁定链表头节点或红黑树根节点
  - **锁粒度**：比JDK 7的Segment锁更细，从段级别缩小到桶级别
  - **进化**：JDK 8中synchronized已进行优化（偏向锁、轻量级锁、重量级锁），性能开销显著降低
  - **使用时机**：主要用于处理哈希冲突时的链表/红黑树操作，如节点插入、删除等

- **volatile 内存可见性**：
  - **应用**：Node节点的val和next字段使用volatile修饰
  - **作用**：确保多线程之间的数据可见性，一个线程修改后立即对其他线程可见
  - **配合CAS**：为无锁操作提供可靠的内存语义保证

- **桶级锁定策略**：
  - **锁定单位**：仅锁定正在操作的哈希桶，而非整个表或段
  - **并发粒度**：不同桶上的操作完全并行，同一桶上的操作串行
  - **锁竞争**：只有当多个线程访问同一个哈希桶时才会发生锁竞争
  - **实际效果**：在哈希分布均匀的情况下，锁竞争概率极低

- **帮助扩容机制**：
  - **设计思想**：将扩容任务分散给多个线程，加速扩容过程
  - **工作原理**：当线程发现表正在扩容时，会检查自己要操作的桶是否已迁移
    - 未迁移：参与扩容，帮助迁移数据
    - 已迁移：直接在新表上操作
  - **同步协调**：使用ForwardingNode节点标记已完成迁移的桶
  - **性能影响**：通过多线程并行工作，显著减少扩容对正常操作的影响

#### 与JDK 7分段锁的对比优势

- **更高的并发度**：桶级锁比Segment锁粒度更细，理论并发度可达到数组长度级别
- **更好的内存利用率**：无需为每个段维护独立的数组和锁结构
- **更灵活的锁策略**：根据操作类型动态选择无锁(CAS)或有锁(synchronized)操作
- **更高效的扩容机制**：多线程并行扩容，避免扩容过程成为性能瓶颈
- **更好的伸缩性**：随着容器大小增长，并发性能不会明显下降（不会受限于固定数量的Segment）

这种混合使用CAS、synchronized和volatile的设计，充分发挥了各种并发控制机制的优势，使ConcurrentHashMap在保证线程安全的同时，提供了接近HashMap的性能表现。


## 七、使用注意事项

1. **null 值处理**：
   - 不允许使用 null 作为键
   - 允许使用 null 作为值

2. **线程安全保证**：
   - get 操作不阻塞（读不加锁）
   - 迭代器弱一致性（不会抛出 ConcurrentModificationException）
   - 不保证原子性复合操作（如 putIfAbsent 是原子的，但 putAll 不是）

3. **性能调优**：
   - 初始容量设置：根据预期并发级别和元素数量
   - 避免热点键：尽量使键的哈希分布均匀
   - 减少锁竞争：避免频繁修改同一键值对

4. **原子操作支持**：
   - ConcurrentHashMap 实现了 ConcurrentMap 接口，提供了额外的原子操作：
     - `putIfAbsent(K key, V value)`：仅当键不存在时才插入
     - `remove(Object key, Object value)`：仅当键值匹配时才删除
     - `replace(K key, V oldValue, V newValue)`：仅当旧值匹配时才替换


## 八、常见问题

1. **为什么不允许 null 键？**
   - 避免歧义：get 返回 null 时，无法区分键不存在还是值为 null
   - 符合 ConcurrentMap 接口规范

2. **弱一致性迭代器意味着什么？**
   - 修改不会抛出 ConcurrentModificationException
   - 不一定反映最新状态
   - 适合并发读取场景

3. **如何避免死锁？**
   - CAS 操作和细粒度锁避免嵌套锁定
   - ForwardingNode 协调多线程扩容

4. **size 方法是否准确？**
   - 非完全准确，返回估计值
   - 并发环境下计数可能变化
   - 精确计数需额外同步

5. **如何选择并发集合？**
   - Map：ConcurrentHashMap
   - List/Set（读多写少）：CopyOnWriteArrayList/CopyOnWriteArraySet
   - 队列：ConcurrentLinkedQueue（无界非阻塞）、LinkedBlockingQueue（有界阻塞）